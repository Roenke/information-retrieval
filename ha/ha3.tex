\subsection*{Homework 3}

\begin{enumerate}
	\item \textbf{[10pt]} Пусть следующая матрица является матрицей смежности ``термин-документ'', 
	описывающей некую коллекцию:
	\begin{equation*}
	C = 
		\begin{bmatrix}
			1 & 1 \\
			0 & 1 \\
			1 & 0
		\end{bmatrix}
	\end{equation*}
	\begin{itemize}
		\item 	Вычислите матрицу совместной встречаемости $CC^T$ . Что собой представляют 
		диагональные элементы этой матрицы?
		\item Убедитесь, что сингулярное разложение матрицы C выглядит следующим образом:
		\begin{equation*}
			\mathcal{U} = 
			\begin{bmatrix}
			-0.816 & 0.000 \\
			-0.408 & 0.707 \\
			-0.408 & 0.707
			\end{bmatrix}, \
			\Sigma = 
			\begin{bmatrix}
			1.732 & 0.000 \\
			0.000 & 1.000
			\end{bmatrix}, and \
			V^T = 
			\begin{bmatrix}
			-0.707 & -0.707 \\
			0.707 & - 0.707
			\end{bmatrix}
		\end{equation*}
		\item Что представляют собой элементы матрицы $C^TC$?
	\end{itemize}
	\textit{Решение.} 
	
	\begin{equation*}
	CC^T = 
	\begin{bmatrix}
		-0.816 & 0.000 \\
		-0.408 & 0.707 \\
		-0.408 & 0.707
	\end{bmatrix}
	\end{equation*}
	
	Диагональные элементы - скалярное произведение строки на себя. В случае матрицы 
	"термин-документ" это соответствует количеству документов, в которых входит данный термин.
	
	Для того, чтобы убедиться, что матрицы $\mathcal{U}, \Sigma, V^T$ являются синглядрным 
	разложением матрицы $C$ достаточно найти их произведение $\mathcal{U} \Sigma V^T$.
	
	 \begin{align*}
	 \mathcal{U} \Sigma V^T = 
	 \begin{bmatrix}
		 -0.816 & 0.000 \\
		 -0.408 & 0.707 \\
		 -0.408 & 0.707
	 \end{bmatrix}
	 \cdot 
	 \begin{bmatrix}
		 1.732 & 0.000 \\
		 0.000 & 1.000
	 \end{bmatrix} \cdot 
	 \begin{bmatrix}
		 -0.707 & -0.707 \\
		 0.707 & - 0.707
	 \end{bmatrix} = \\
	 \begin{bmatrix}
		 -1.41331 & 0 \\
		 -0.706656 & 0.707 \\
		 -0.706656 & 0.707 
	 \end{bmatrix} \cdot
	 \begin{bmatrix}
		 -0.707 & -0.707 \\
		 0.707 & - 0.707
	 \end{bmatrix}
	 = 
	 \begin{bmatrix}
		 1 & 1 \\
		 0 & 1 \\
		 1 & 0
	 \end{bmatrix} = C,
	 \end{align*}
	 
	 Вычислим матрицу $C^TC$. 
	 
	 \begin{equation*}
	 C^TC = 
	 \begin{bmatrix}
		 2 & 1 \\
		 1 & 2
	 \end{bmatrix}
	 \end{equation*}
	 
	 Заметим, что элементы этой матрицы - это скалярные произведения строк матрицы $C$, то есть 
	 это скалярные произведения векторов термин - документы. Чем больше это произведения, тем 
	 ближе эти вектора, некоторые модели выводят из этого, что слова и по смыслу тоже близки.
	
	\item \textbf{[10pt]} Для чего используются распределения Дирихле $Dir(\alpha)$ и $Dir(\beta)$ 
	в тематических моделях? Что контролируют параметры $\alpha$ и $\beta$ (нужно иметь в виду, что 
	$\alpha$ и $\beta$ - это наборы/векторы параметров)? Какие значения этих параметром имеет 
	смысл использовать и почему?
	
	\textit{Решение.}
	
	Введем обозначения: $k$ - количество тем, $n$ - размер словаря, $m$ - количество документов.
	
	\begin{itemize}
		\item $Dir(\alpha)$ - позволяет получить распределение тем по документу. $\alpha$ - вектор 
		из $k$ положительных вещественных значений. $i$ - ая компонента задает вес темы под 
		номером $i$ в документе. Обычно компоненты вектора - одинаковые (если нет априорного 
		знания о распределении тем) значения меньше 1 - порядка - $\frac{1}{k}$. Не стоит брать 
		слишком большие значения $\alpha_i$, т.к. в этом случае тем в одном документе может 
		оказаться слишком мало, и наоборот, слишком много, если взять очень маленькие значения для 
		$\alpha_i$. 
		
		\item $Dir(\beta)$ - позволяет получить распределение слов по темам. $\beta$ - вектор из 
		$n$ положительных вещественных значений. $i$ - ая компонента задает вес слова под номером 
		$i$ в теме. Из тех же соображений стоит взять значения сильно меньше 1 - порядка 
		$\frac{1}{n}$, чтобы в одну тему попало несколько слов, а не одно/сразу все, может 
		получиться в крайних случаях.
	\end{itemize}
	
	\item \textbf{[5pt]} Пользователь в дополнение к кликам по гиперссылкам на странице, которую 
	он в данный момент просматривает, может перейти по кнопке "назад" и вернуться на предыдущую 
	страницу. Можно ли эту ситуацию смоделировать с помощью марковской цепи и как? Как 
	смоделировать повторяющиеся щелчки на кнопке "назад"?
	
	\textit{Решение.}
	
	Да, это возможно, но нужно с каждой вершиной связать стек, и добавлять в него предыдущую 
	вершину пути, при попадании в вершину. А при переходе из вершины нужно добавить вариант - 
	перейти "назад", с фиксированной вероятностью (либо более сложной). После перехода, элемент со 
	стека нужно снять. Использование стека позволит так же выполнять повторяющиеся щелчки, даже 
	когда движение "назад" образует циклы. 
	
	Осталось решить проблему, что цепи Маркова не знают ничего про стек. Но зато они могут 
	содержать бесконечное (счетное число вершин). Элементы стека - это номера вершин исходной цепи 
	Маркова, значит, стек имеет счетное число состояний (вообще говоря, даже если множество 
	состояний исходной цепи тоже счетное, но количество сайтов - конечное число). Теперь вершину и 
	состояние стека можно вынести в отдельную вершину. Переходы "назад" и "вперед" просто переходят 
	в вершины с соответствующими состояниями стека.

	\item \textbf{[10pt]} Объясните основную идею метода $Ranking \ SVM$ – одного из первых 
	методов	\textit{pairwise learning to rank [1]}. В частности, опишите, что оптимизирует этот 
	метод, какие тренировочные данные он использует и как получить эти данные.
	
	\textit{Решение.}
	
	Цель - имея только данные логов получить функцию ранжирования. Идея - документы, которые внизу выдачи, но при этом были выбраны пользователем релевантнее запросу $q$, тех, которые были выше, но пользователь их пропустил.
	
	Данные - тройки $(q, r, c)$ - где $q$ - запрос, $r$ - ранжирование, $c$ - набор кликов. Чтобы 
	их собрать нужно модифицировать результат поисковой выдачи и воспользоваться прокси сервером 
	(данные собираются неявно для пользователя). Алгоритм следующий - прежде чем показать 
	пользователю выдачу, она проходит через прокси, запросу присваивается уникальный $id$, а 
	ссылки на документы заменяются на ссылки на этот же прокси (с сохранением исходного адреса 
	документа) и в таком виде передается пользователю. После клика по документу запрос приходит на 
	прокси сервер, где можно получить данные о клике для запроса с таким $id$ и перенаправить 
	пользователя на "настоящий" документ.
	
	После того, как данные собраны из них можно извлечь всё предпочтения пользователей - некоторое 
	отношение частичного порядка на множестве документов. Считается, что документ $d_1$ 
	предпочтительнее $d_2$, если $d_1$ оказался ниже в выдаче, при этом по $d_1$ был клик, а по 
	$d_2$ нет. Пару $(d_1, d_2)$ будет называть предпочтение.
	
	Ранжирование считается хорошим, если нарушает как можно меньше предпочтений. Таким образом 
	тренировочная выборка это набор пар (запрос, набор предпочтений). Искомая функция - функция 
	ранжирования $f(q)$. Оптимизируемая величина - средняя доля нарушенных предпочтений среди 
	элементов обучающей выборки (вообще, это довольно грубое утверждение, оптимизируется Kendall's 
	$\tau$)
	
	\item \textbf{[5pt]} Объясните методы нормировки \textit{Z-Score} и \textit{Sum} с точки 
	зрения предполагаемого статистического распределения нормируемых данных. Т.е. какие 
	распределения предполагают эти методы и что они делают с предполагаемыми распределениями?
	
	\textit{Решение.}
	\begin{itemize}
		\item \textit{Z-Score} - основывается на предположении, что данные распределены нормально. Переводит результаты к стандартному нормальному распределению - с нулевым матожиданием и единичной дисперсией.
		\begin{align*}
			s_{norm} &= \frac{s - \mu}{\sigma}, where\\
			\mu &= \frac{1}{n} \sum\limits_{i = 1}^n s_n\\
			\sigma &= \sqrt{\frac{1}{n} \sum\limits_{i = 1}^n (s_i - \mu)}
		\end{align*}
		
		\item \textit{Sum} - основывается на предположении, что данные распределены экспоненциально.
		\begin{equation*}
			s_{norm} = \frac{s'}{\sum\limits_{i = 1}^{n}s'_i}, where \ s' = s - min, 
		\end{equation*}
	\end{itemize}
	
	
	\item \textbf{[5pt]} Рассмотрим задачу поиска экспертов \textit{(expert finding)} в той или 
	иной области знаний, где область знаний – это запрос, а эксперты – это сущности, которые нужно 
	отранжировать по запросу.
		
	Например, по запросу \textit{``information retrieval''} из множества всех известных 
	экспертов	нужно выбрать (и отранжировать) ``Bruce Croft'', ``Christopher Manning'', 
	``Maarten de Rijke'', ``Ilya Markov'' и т.д.
	
	Каждый эксперт является автором некоторого количества документов (научные статьи, патенты, 
	письма и т.д.). Какие из методов, рассмотренных в лекциях, можно использовать для задачи 
	поиска экспертов и каким образом?
	
	\textit{Решение.}
	\item \textbf{[5pt]} Выведите формулы для подсчета полной и условной вероятности клика для	
	позиционной кликовой модели \textit{(PBM)}. Как они соотносятся друг с другом и почему?
	
	\textit{Решение.}
	\begin{align*}
		P(C_u &|E_{r_u} = 1 ) = \alpha_{uq}\\
		P(C_u &|A_u = 1) = \gamma_{r_u}\\
		P(C_u &|E_{r_u} = 0 , A_u = 0) = 0\\
		P(C_u &|E_{r_u} = 0 , A_u = 1) = 0\\
		P(C_u &|E_{r_u} = 1 , A_u = 0) = 0\\
		P(C_u &|E_{r_u} = 1 , A_u = 1) = 1 \\
		P(C_u &= 1) = P(E_{r_u} = 1) \cdot P(A_u = 1) = \gamma_{r_u} \cdot \alpha_{uq}
	\end{align*}
	
	\item \textbf{[5pt]} Рассмотрим кликовую модель \textit{dynamic Bayesian network (DBN)}. Она 
	включает три типа параметров:
	
	\begin{itemize}
		\item Аттрактивность $\alpha_{uq}$ – пользователю понравился сниппет.
		\item Удовлетворенность $\sigma_{uq}$ – пользователю понравился сам документ.
		\item Вероятность продолжить чтение сниппетов $\gamma$ в случае неудовлетворенности.
	\end{itemize}
	
	Параметр $\gamma$ обычно близок к 1, поэтому будет считать, что $\gamma = 1$. Как в этом 
	случае подсчитать значения параметров $\alpha_{uq}$ и $\sigma_{uq}$ на основании некоторого 
	имеющегося лога кликов?
	
	\textit{Решение.}
\end{enumerate}
