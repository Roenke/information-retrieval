\subsection*{Homework 3}

\begin{enumerate}
	\item \textbf{[10pt]} Пусть следующая матрица является матрицей смежности ``термин-документ'', 
	описывающей некую коллекцию:
	\begin{equation*}
	C = 
		\begin{bmatrix}
			1 & 1 \\
			0 & 1 \\
			1 & 0
		\end{bmatrix}
	\end{equation*}
	\begin{itemize}
		\item 	Вычислите матрицу совместной встречаемости $CC^T$ . Что собой представляют 
		диагональные элементы этой матрицы?
		\item Убедитесь, что сингулярное разложение матрицы C выглядит следующим образом:
		\begin{equation*}
			\mathcal{U} = 
			\begin{bmatrix}
			-0.816 & 0.000 \\
			-0.408 & 0.707 \\
			-0.408 & 0.707
			\end{bmatrix}, \
			\Sigma = 
			\begin{bmatrix}
			1.732 & 0.000 \\
			0.000 & 1.000
			\end{bmatrix}, and \
			V^T = 
			\begin{bmatrix}
			-0.707 & -0.707 \\
			0.707 & - 0.707
			\end{bmatrix}
		\end{equation*}
		\item Что представляют собой элементы матрицы $C^TC$?
	\end{itemize}
	\textit{Решение.} 
	
	\begin{equation*}
	CC^T = 
	\begin{bmatrix}
		-0.816 & 0.000 \\
		-0.408 & 0.707 \\
		-0.408 & 0.707
	\end{bmatrix}
	\end{equation*}
	
	Диагональные элементы - скалярное произведение строки на себя. В случае матрицы 
	"термин-документ" это соответствует количеству документов, в которых входит данный термин.
	
	Сингулярное разложение матрицы $C$ так выглядень не может, т.к. в сингулярном разложении есть требование, что матрица $\mathcal{U}$ - унитарная. Тут это очевидно не так - она прямоугольная. Для унитарная матрица должна быть по крайней мере квадратной (иначе нет обратной).
	 
	 Вычислим матрицу $C^TC$. 
	 
	 \begin{equation*}
	 C^TC = 
	 \begin{bmatrix}
		 2 & 1 \\
		 1 & 2
	 \end{bmatrix}
	 \end{equation*}
	 
	 Заметим, что элементы этой матрицы - это скалярные произведения строк матрицы $C$, то есть 
	 это скалярные произведения векторов термин - документы. Чем больше это произведения, тем 
	 ближе эти вектора, некоторые модели выводят из этого, что слова и по смыслу тоже близки. Т,к. 
	 у матрица встречаемости а не частоты, то элементы $C^TC$ это количество общих слов в 
	 соответствующих документах.
	
	\item \textbf{[10pt]} Для чего используются распределения Дирихле $Dir(\alpha)$ и $Dir(\beta)$ 
	в тематических моделях? Что контролируют параметры $\alpha$ и $\beta$ (нужно иметь в виду, что 
	$\alpha$ и $\beta$ - это наборы/векторы параметров)? Какие значения этих параметром имеет 
	смысл использовать и почему?
	
	\textit{Решение.}
	
	Введем обозначения: $k$ - количество тем, $n$ - размер словаря, $m$ - количество документов.
	
	\begin{itemize}
		\item $Dir(\alpha)$ - позволяет получить распределение тем по документу. $\alpha$ - вектор 
		из $k$ положительных вещественных значений. $i$ - ая компонента задает вес темы под 
		номером $i$ в документе. Обычно компоненты вектора - одинаковые (если нет априорного 
		знания о распределении тем) значения меньше 1 - порядка - $\frac{1}{k}$. Не стоит брать 
		слишком большие значения $\alpha_i$, т.к. в этом случае тем в одном документе может 
		оказаться слишком мало, и наоборот, слишком много, если взять очень маленькие значения для 
		$\alpha_i$. 
		
		\item $Dir(\beta)$ - позволяет получить распределение слов по темам. $\beta$ - вектор из 
		$n$ положительных вещественных значений. $i$ - ая компонента задает вес слова под номером 
		$i$ в теме. Из тех же соображений стоит взять значения сильно меньше 1 - порядка 
		$\frac{1}{n}$, чтобы в одну тему попало несколько слов, а не одно/сразу все, может 
		получиться в крайних случаях.
	\end{itemize}
	
	\item \textbf{[5pt]} Пользователь в дополнение к кликам по гиперссылкам на странице, которую 
	он в данный момент просматривает, может перейти по кнопке "назад" и вернуться на предыдущую 
	страницу. Можно ли эту ситуацию смоделировать с помощью марковской цепи и как? Как 
	смоделировать повторяющиеся щелчки на кнопке "назад"?
	
	\textit{Решение.}
	
	Да, это возможно, но нужно с каждой вершиной связать стек, и добавлять в него предыдущую 
	вершину пути, при попадании в вершину. А при переходе из вершины нужно добавить вариант - 
	перейти "назад", с фиксированной вероятностью (либо придумать более сложной способ расчета 
	такой вероятности). После перехода "назад" нужно снять элемент со стека в вершине, из которой 
	этот переход произведен. Использование стека позволит так же выполнять повторяющиеся щелчки, 
	даже когда движение "назад" образует циклы. 
	
	Осталось решить проблему, что цепи Маркова ничего не знают про стек. Но зато они могут 
	содержать бесконечное (счетное число вершин). Элементы стека - это номера вершин исходной цепи 
	Маркова (эта цепь конечная, т.к. страниц в интернете конечное число), значит, стек имеет 
	счетное число состояний (счетное число элементов, каждый элемент ограничен $\Rightarrow$ их 
	можно пересчитать). Теперь вершину и состояние стека можно вынести в отдельную вершину. 
	Переходы "назад" и "вперед" просто переходят в вершины с соответствующими состояниями стека.

	\item \textbf{[10pt]} Объясните основную идею метода $Ranking \ SVM$ – одного из первых 
	методов	\textit{pairwise learning to rank [1]}. В частности, опишите, что оптимизирует этот 
	метод, какие тренировочные данные он использует и как получить эти данные.
	
	\textit{Решение.}
	
	Цель - имея только данные логов получить функцию ранжирования. Идея - документы, которые внизу выдачи, но при этом были выбраны пользователем релевантнее запросу $q$, тех, которые были выше, но пользователь их пропустил.
	
	Данные - тройки $(q, r, c)$ - где $q$ - запрос, $r$ - ранжирование, $c$ - набор кликов. Чтобы 
	их собрать нужно модифицировать результат поисковой выдачи и воспользоваться прокси сервером 
	(данные собираются неявно для пользователя). Алгоритм следующий - прежде чем показать 
	пользователю выдачу, она проходит через прокси, запросу присваивается уникальный $id$, а 
	ссылки на документы заменяются на ссылки на этот же прокси (с сохранением исходного адреса 
	документа) и в таком виде передается пользователю. После клика по документу запрос приходит на 
	прокси сервер, где можно получить данные о клике для запроса с таким $id$ и перенаправить 
	пользователя на "настоящий" документ.
	
	После того, как данные собраны из них можно извлечь всё предпочтения пользователей - некоторое 
	отношение частичного порядка на множестве документов. Считается, что документ $d_1$ 
	предпочтительнее $d_2$, если $d_1$ оказался ниже в выдаче, при этом по $d_1$ был клик, а по 
	$d_2$ нет. Пару $(d_1, d_2)$ будет называть предпочтение.
	
	Ранжирование считается хорошим, если нарушает как можно меньше предпочтений. Таким образом 
	тренировочная выборка это набор пар (запрос, набор предпочтений). Искомая функция - функция 
	ранжирования $f(q)$. Оптимизируемая величина - средняя доля нарушенных предпочтений среди 
	элементов обучающей выборки (вообще, это довольно грубое утверждение, оптимизируется Kendall's 
	$\tau$)
	
	\item \textbf{[5pt]} Объясните методы нормировки \textit{Z-Score} и \textit{Sum} с точки 
	зрения предполагаемого статистического распределения нормируемых данных. Т.е. какие 
	распределения предполагают эти методы и что они делают с предполагаемыми распределениями?
	
	\textit{Решение.}
	\begin{itemize}
		\item \textit{Z-Score} - основывается на предположении, что данные распределены нормально. Переводит результаты к стандартному нормальному распределению - с нулевым матожиданием и единичной дисперсией.
		\begin{align*}
			s_{norm} &= \frac{s - \mu}{\sigma}, where\\
			\mu &= \frac{1}{n} \sum\limits_{i = 1}^n s_n\\
			\sigma &= \sqrt{\frac{1}{n} \sum\limits_{i = 1}^n (s_i - \mu)}
		\end{align*}
		
		\item \textit{Sum} - основывается на предположении, что данные распределены экспоненциально. После нормировки данные распределены по прежнему экспоненциально, но уже в пределах $[0, 1]$
		\begin{equation*}
			s_{norm} = \frac{s'}{\sum\limits_{i = 1}^{n}s'_i}, where \ s' = s - min, 
		\end{equation*}
	\end{itemize}
	
	
	\item \textbf{[5pt]} Рассмотрим задачу поиска экспертов \textit{(expert finding)} в той или 
	иной области знаний, где область знаний – это запрос, а эксперты – это сущности, которые нужно 
	отранжировать по запросу.
		
	Например, по запросу \textit{``information retrieval''} из множества всех известных 
	экспертов	нужно выбрать (и отранжировать) ``Bruce Croft'', ``Christopher Manning'', 
	``Maarten de Rijke'', ``Ilya Markov'' и т.д.
	
	Каждый эксперт является автором некоторого количества документов (научные статьи, патенты, 
	письма и т.д.). Какие из методов, рассмотренных в лекциях, можно использовать для задачи 
	поиска экспертов и каким образом?
	
	\textit{Решение.} 
	
	
	\begin{itemize}
		\item Заметим, что документы имеют важную особенность - ссылки друг на друга. Поэтому стоит 
		рассматривать методы, которые используют данные ссылки. Т.к. у нас есть запрос, то лучше 
		использовать \textit{HITS}, чтобы отранжировать. Осталось определить ранжирование для 
		авторов. Можно поступить следующим образом: отранжируем их по количеству статей в топ 50 
		выдачи \textit{HITS}.
		\item С другой стороны, можно заметить, что статьи по одной теме могут использовать одну 
		терминологию. Поэтому могут быть использованы тематические модели. Сначала определим к 
		какой теме относится запрос, затем найдем документы, которые подходят больше всего под 
		полученную тему. Ранжирование можно использовать с предыдущего шага, либо использовать 
		\textit{PageRank}, чтобы определить у кого из авторов топоввых документов выше индекс цитирования.
	\end{itemize}
	
	\item \textbf{[5pt]} Выведите формулы для подсчета полной и условной вероятности клика для	
	позиционной кликовой модели \textit{(PBM)}. Как они соотносятся друг с другом и почему?
	
	\textit{Решение.} Заметим, что принятие решение просматривать ли сниппет на фиксированной позиции не зависит от предыдущих событий, поэтому условная и полная вероятности совпадают.
	\begin{align*}
		P(C_u &|E_{r_u} = 1 ) = \alpha_{uq}\\
		P(C_u &|A_u = 1) = \gamma_{r_u}\\
		P(C_u &|E_{r_u} = 0 , A_u = 0) = 0\\
		P(C_u &|E_{r_u} = 0 , A_u = 1) = 0\\
		P(C_u &|E_{r_u} = 1 , A_u = 0) = 0\\
		P(C_u &|E_{r_u} = 1 , A_u = 1) = 1 \\
		P(C_u &= 1) = P(E_{r_u} = 1) \cdot P(A_u = 1) = \gamma_{r_u} \cdot \alpha_{uq}
	\end{align*}
	
	\item \textbf{[5pt]} Рассмотрим кликовую модель \textit{dynamic Bayesian network (DBN)}. Она 
	включает три типа параметров:
	
	\begin{itemize}
		\item Аттрактивность $\alpha_{uq}$ – пользователю понравился сниппет.
		\item Удовлетворенность $\sigma_{uq}$ – пользователю понравился сам документ.
		\item Вероятность продолжить чтение сниппетов $\gamma$ в случае неудовлетворенности.
	\end{itemize}
	
	Параметр $\gamma$ обычно близок к 1, поэтому будет считать, что $\gamma = 1$. Как в этом 
	случае подсчитать значения параметров $\alpha_{uq}$ и $\sigma_{uq}$ на основании некоторого 
	имеющегося лога кликов?
	
	\textit{Решение.}
	
	Пусть в логе для каждого клика хранится номер сессии, в которой совершен клик, выдача и номер документа, на который кликнул пользователь. Под сессией будем понимать действия пользователя в рамках одного поискового запроса, т.е. переформулирование запроса, это начало новой сессии (т.е. запрос в рамках одной сессии не меняется). Оценим параметры на основе этого лога.
	\begin{itemize}
		\item $\alpha_{uq}$ - найдем сессии из лога, такие что, в них был запрос $q$, а в выдаче документ $u$. Нас будут интересовать лишь те сессии, где сниппет для $u$ был просмотрен. Согласно $DBN$ - это сессии в которых был клик по сниппету для $u$, а так же сессии в которых был клик по сниппетам, расположенным ниже чем сниппет для $u$. Обозначим это множество $A_{uq}$. Для оценки аттрактивности нам нужно узнать сессий из $A_{uq}$ содержат клик по сниппету для $u$. Обозначим это множество - $\mathcal{A}$. Получим оценку:
		\begin{equation*}
			\alpha_{uq} = \frac{|\mathcal{A}|}{|A_{uq}|}
		\end{equation*}
		
		\item $\sigma_{uq}$ - найдем сессии с запросом $q$, в которых был клик по сниппету для $u$ - обозначим $B_{uq}$. Выберем среди них такие сессии, в которых клик по сниппету для документа $u$ был последним. Обозначим это множество $\mathcal{B}$. Получим оценку:
		\begin{equation*}
			\sigma_{uq} = \frac{|\mathcal{B}|}{|B_{uq}|}
		\end{equation*}
	\end{itemize}
\end{enumerate}
