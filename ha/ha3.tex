\subsection*{Homework 3}

\begin{enumerate}
	\item \textbf{[10pt]} Пусть следующая матрица является матрицей смежности ``термин-документ'', 
	описывающей некую коллекцию:
	\begin{equation*}
	C = 
		\begin{bmatrix}
		1 & 1 \\
		0 & 1 \\
		1 & 0
		\end{bmatrix}
	\end{equation*}
	\begin{itemize}
		\item 	Вычислите матрицу совместной встречаемости $CC^T$ . Что собой представляют 
		диагональные элементы этой матрицы?
		\item Убедитесь, что сингулярное разложение матрицы C выглядит следующим образом:
		\begin{equation*}
			\mathcal{U} = 
			\begin{bmatrix}
			-0.816 & 0.000 \\
			-0.408 & 0.707 \\
			-0.408 & 0.707
			\end{bmatrix}, \
			\Sigma = 
			\begin{bmatrix}
			1.732 & 0.000 \\
			0.000 & 1.000
			\end{bmatrix}, and \
			V^T = 
			\begin{bmatrix}
			-0.707 & -0.707 \\
			0.707 & - 0.707
			\end{bmatrix}
		\end{equation*}
		\item Что представляют собой элементы матрицы $C^TC$?
	\end{itemize}
	\textit{Решение.} 
	
	\item \textbf{[10pt]} Для чего используются распределения Дирихле $Dir(\alpha)$ и $Dir(\beta)$ 
	в тематических моделях? Что контролируют параметры $\alpha$ и $\beta$ (нужно иметь в виду, что 
	$\alpha$ и $\beta$ - это наборы/векторы параметров)? Какие значения этих параметром имеет 
	смысл использовать и почему?
	
	\textit{Решение.}
	
	\item \textbf{[5pt]} Пользователь в дополнение к кликам по гиперссылкам на странице, которую 
	он в данный момент просматривает, может перейти по кнопке "назад" и вернуться на предыдущую 
	страницу. Можно ли эту ситуацию смоделировать с помощью марковской цепи и как? Как 
	смоделировать повторяющиеся щелчки на кнопке "назад"?
	
	\textit{Решение.} 
	\item \textbf{[10pt]} Объясните основную идею метода $Ranking \ SVM$ – одного из первых 
	методов	\textit{pairwise learning to rank [1]}. В частности, опишите, что оптимизирует этот 
	метод, какие тренировочные данные он использует и как получить эти данные.
	
	\textit{Решение.}
	\item \textbf{[5pt]} Объясните методы нормировки \textit{Z-Score} и \textit{Sum} с точки 
	зрения предполагаемого статистического распределения нормируемых данных. Т.е. какие 
	распределения предполагают эти методы и что они делают с предполагаемыми распределениями?
	
	\textit{Решение.}
	\item \textbf{[5pt]} Рассмотрим задачу поиска экспертов \textit{(expert finding)} в той или 
	иной области знаний, где область знаний – это запрос, а эксперты – это сущности, которые нужно 
	отранжировать по запросу.
		
	Например, по запросу \textit{``information retrieval''} из множества всех известных 
	экспертов	нужно выбрать (и отранжировать) ``Bruce Croft'', ``Christopher Manning'', 
	``Maarten de Rijke'', ``Ilya Markov'' и т.д.
	
	Каждый эксперт является автором некоторого количества документов (научные статьи, патенты, 
	письма и т.д.). Какие из методов, рассмотренных в лекциях, можно использовать для задачи 
	поиска экспертов и каким образом?
	
	\textit{Решение.}
	\item \textbf{[5pt]} Выведите формулы для подсчета полной и условной вероятности клика для	
	позиционной кликовой модели \textit{(PBM)}. Как они соотносятся друг с другом и почему?
	
	\textit{Решение.}
	\item \textbf{[5pt]} Рассмотрим кликовую модель \textit{dynamic Bayesian network (DBN)}. Она 
	включает три типа параметров:
	
	\begin{itemize}
		\item Аттрактивность $\alpha_{uq}$ – пользователю понравился сниппет.
		\item Удовлетворенность $\sigma_{uq}$ – пользователю понравился сам документ.
		\item Вероятность продолжить чтение сниппетов $\gamma$ в случае неудовлетворенности.
	\end{itemize}
	
	Параметр $\gamma$ обычно близок к 1, поэтому будет считать, что $\gamma = 1$. Как в этом 
	случае подсчитать значения параметров $\alpha_{uq}$ и $\sigma_{uq}$ на основании некоторого 
	имеющегося лога кликов?
	
	\textit{Решение.}
\end{enumerate}
