\subsection*{Homework 2}

\begin{enumerate}
	\item \textbf{[10pt]} Рассмотренные методы исправления опечаток не работают напрямую при 
	пропуске пробела (например, \textit{informationretrieval}). Опишите, как исправлять такие 
	опечатки (не обязательно на основе рассмотренных методов).
	
	\textit{Решение.} Можно пойти двумя путями: увеличить размер индекса и время обработки запроса
	\begin{itemize}
		\item увеличение размера индекса - линейное увеличение - рассматривать как слова ещё и 
		пары слов, которые были соседними в исходном документе. Полиномиальное увеличение размера 
		индекса - рассматривать все пары/тройки/четверки/... слов, которые могут образовывать 
		слова. Наверное на практике такое сложно применить, хотя при небольшом словаре этот 
		способ может быть рабочим.  
		\item увеличение времени на обработку запроса. Пытаем разбить слово на несколько слов 
		всеми возможными способами (сначала на 2, потом на 3 и так до какого-то разумного 
		лимита). Так же можно пытаться найти соответствие префикса какому-либо слову из словаря, 
		и потом рекурсивно повторить операцию на суффиксе.
	\end{itemize}
	
	\item \textbf{[5pt]} Мы рассмотрели два типа методов для рекомендации запросов, аналогичных 
	заданному запросу:
	\begin{enumerate}
		\item Рекомендовать запросы, встречающиеся в одной сессии с заданным запросом.
		\item Рекомендовать те запросы, у которых множество кликнутых результатов сильно 	
		пересекается с аналогичным множеством для заданного запроса.
	\end{enumerate}

	Какие еще методы для рекомендации запросов вы можете предложить?
	
	\textit{Решение.} 
	\begin{itemize}
		\item Запросы других людей, за последние $N$ минут, которые похожи на текущий запрос 
		(например, пересекаются по некоторым словам). Пример: $q=$\textit{Презентация ...}, 
		возможная подсказка \textit{"Презентация apple"}. Т.к. она (условно) была вчера вечером и 
		уже многие сегодня весь день хотели найти об этом информацию.
		\item Запросы других людей, которые были в это же время суток/в тот день недели/в таких 
		же числах месяца/в то же время года, которые похожи на текущий запрос (например, 
		пересекаются по некоторым словам). Пример: пятница, полдень $q=$ \textit{"погода на "}. 
		Логичнее дополнить как \textit{"на выходные"}. То же самое работает и для праздников.
		\item Запросы которые уже встречались от этого же пользователя и похож на текущий. Часто 
		бывает нужно повторить поиск, но не всегда пользователь запоминает абсолютно точно текст 
		запроса, но это может влиять на выдачу.
		\item Если известна геопозиция пользователя(либо история запросов с какими-либо 
		гео-данными), то можно дополнить запрос соответствующей информацией.
		
		Пример: $q=$\textit{Погода в}. Возможная рекомендация $"Погода в Турции"$, если он уже 
		упоминал Турцию, когда искал билеты и отель.
	\end{itemize}
	\item \textbf{[5pt]} Вы планируете использовать следующие методы поиска: модель векторного 
	пространства с весами TF-IDF, BM25, языковую модель. Какую минимальную информацию должен 
	содержать индекс, чтобы поддерживать эффективное использование этих методов? Какую информацию 
	нет смысла хранить в индексе? Как ее нужно хранить? Дайте развернутый ответ.
	
	\textit{Решение.} 
	
	\item \textbf{[10pt]} Отранжируйте документы из таблицы 1 по запросу "car insurance" с 
	использованием модели векторного пространства и весов TF-IDF.
	
	\begin{tabular}{c | c | c c c}
		\multirow{2}{*}{Слово} & \multirow{2}{*}{idf} & \multicolumn{3}{c}{tf} \\ \cline{3-5}
		& & Документ 1 & Документ 2 & Документ 3 \\ \hline	
		car & 1.65 & 27 & 4 & 24 \\
		auto & 2.08 & 3 & 33 & 0 \\
		insurance & 1.62 & 0 & 33 & 29 \\
		best & 1.60 & 14 & 0 & 17 \\
	\end{tabular}
	
	\item \textbf{[5pt]} Рассмотрим следующий запрос и три результата.
	\begin{enumerate}
		\item[Q] information retrieval course
		\item[D1] Information Retrieval and Web Search
		\item[D2] Introduction to Information Retrieval
		\item[D3] Text Retrieval and Search Engines
	\end{enumerate}
	
	Результаты $1$ и $3$ – это страницы соответствующих курсов, поэтому пользователь пометил их 
	как релевантные. Результат $2$ – это страница с книгой, поэтому пользователь пометил его как 
	нерелевантный.
	
	Примените алгоритм Роккио и выпишите вектор запроса после учета обратной связи по 
	релевантности. Элементы вектора перечислите в алфавитном порядке. Считайте, что компоненты 
	векторов содержат только частоты слов (без обратной документной частоты и нормировки). 
	Параметры алгоритма Роккио: $\alpha = 1, \beta = 0.75, \gamma = 0.25.$s

	\item \textbf{[10pt]} Выпишите формулу \textit{BM25} для длинных запросов. Опишите ее 
	составляющие. Каким образом каждая составляющая влияет на ранжирование (т.е. что происходит	с 
	ранжированием результатов при изменении каждой из составляющих)?

	\item \textbf{[10pt]} Пусть бинарная случайная величина $X_t$ – это индикатор того, что слово 
	$t$	встречается в документе (т.е. $X_t = 1$, если слово $t$ есть в документе, и $X_t = 0$, 
	если слова $t$ нет в документе). $P_t = P(X_t = 1 \big| d)$ – это вероятность того, что слово 
	$t$ встречается в документе $d$. 
	
	Примените метод максимального правдоподобия \textit{(MLE)} для формального вычисления $P_t$ и 
	покажите, что $P_t = \dfrac{tf(t,d)} {dl(d)}$, где 
	\begin{itemize}
		\item $tf(t, d)$ – это частота слова $t$ в документе $d$, 
		\item $dl(d)$ – это длина документа $d$.
	\end{itemize}
	
	\item \textbf{[5pt]} Рассмотрим коллекцию из двух документов.
	\begin{enumerate}
		\item[D1] A language model is a probability distribution over words or sequences of words.
		\item[D2] A language model is used in many natural language processing applications.
	\end{enumerate}

	Выпишите сглаженную униграмную языковую модель для каждого документа. Используйте сглаживание 
	\textit{Jelinek-Mercer} с параметром $\lambda = 0.5$. Отранжируйте эти документы по запросу 
	\textit{"many words"}.
\end{enumerate}
